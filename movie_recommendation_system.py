# -*- coding: utf-8 -*-
"""Movie Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XNIZx-7xqjQ9Tq5aHZReU6S4VgOdp55B
"""

import pandas as pd
import numpy as np

cast=pd.read_csv("tmdb_5000_credits.csv")
cast.head()

movie=pd.read_csv("tmdb_5000_movies.csv")
movie.head()

df=pd.merge(cast,movie,on="title")
df.head()

df.sample()

#data cleaning
df.isnull().sum()

df.shape

#remove homepage remaining fill with mode

df=df.drop("homepage",axis=1)

df

print(df['overview'][0])

df=df.loc[:,["genres","id","keywords","original_language","title","overview","cast","crew"]]

df.head()

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

df['original_language'].value_counts()

feature_df=df.copy()

import ast

def get_genre(genre):
  genre=ast.literal_eval(genre)
  l=[]
  for i in genre:
    l.append(i['name'])
  return l

df['genres']=df['genres'].apply(get_genre)

df['keywords']=df['keywords'].apply(get_genre)

df['cast'][0]

def get_cast(cast):
  cast=ast.literal_eval(cast)
  chars=[]
  for character in range(0,3):
    try:
      chars.append(cast[character]['name'])
    except:
      break
  return chars

df['cast']=df['cast'].apply(get_cast)

df.head(2)

df['crew'][0]

def get_director(crew):
  crew=ast.literal_eval(crew)
  for i in crew:
    if i['job'].casefold()=='Director'.casefold():
      return i['name']
  return np.nan

df['crew']=df['crew'].apply(get_director)

df.head()

df['genres'][1]

#creating corpus of genres keywords original_language overview cast crew

df.dropna(inplace=True)

def con(l):
  return " ".join(l)

for col in ["genres","keywords","cast"]:
  df[col]=df[col].apply(con)

df.head()

cols=['genres','keywords','original_language','overview',"cast","crew"]

#preprocessing

def lower(col):
  df[col]=df[col].str.lower()

for col in cols:
  lower(col)

df.head(2)

df.reset_index(drop=True, inplace=True)

corpus_tags=[]
for i in range(df.shape[0]):
  tags=[]
  for tag in df.loc[i,cols]:
    tags.append(tag)
  corpus_tags.append(' '.join(tags))
corpus_tags

import string

punc=string.punctuation

punc

for i in range(len(corpus_tags)):
  for char in punc:
    corpus_tags[i]=corpus_tags[i].replace(char," ")

corpus_tags[0]

import nltk

from nltk.corpus import stopwords
nltk.download("stopwords")

words=stopwords.words('english')

for i in range(len(corpus_tags)):
  words_corpus=corpus_tags[i].split()
  final_words=[]
  for word in words_corpus:
    if word not in words:
      final_words.append(word)
  corpus_tags[i]=" ".join(final_words)

corpus_tags[0]

nltk.download("punk_t")

nltk.download("punkt")

from nltk.stem import PorterStemmer

ps=PorterStemmer()

ps.stem("walking")

for i in range(len(corpus_tags)):
  words_corpus=corpus_tags[i].split()
  final_words=[]
  for word in words_corpus:
    final_words.append(ps.stem(word))
  corpus_tags[i]=" ".join(final_words)

corpus_tags[0]

from sklearn.feature_extraction.text import CountVectorizer

cv=CountVectorizer(max_features=5000)

bow=cv.fit_transform(corpus_tags)

bow=bow.toarray()

bow

movies=df['title']

movies=list(movies)

embedings=pd.DataFrame(data=bow)

movies_list=pd.DataFrame({"Title":movies,"id":list(df['id'])})

movies_list.head()

embedings.to_csv("embeddings.csv")

movies_list.to_csv("movies.csv")

from sklearn.neighbors import NearestNeighbors

ne=NearestNeighbors(n_neighbors=6,algorithm='brute',metric='cosine')

ne.fit(np.array(bow))

dist,ind=ne.kneighbors(bow[1].reshape(1, -1))

for i in ind[0]:
  print(movies[i])

movies[1]

